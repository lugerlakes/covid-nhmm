{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e875377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Rt panels for Copula simulations: Cori (obs & Copula) + WT (stable)\n",
    "# - Load simulations from CSV (R: simulated_cases_severity_weighted_v2.csv)\n",
    "# - Calculate Cori (observed and posterior mixture over simulations)\n",
    "# - Calculate stable WT (observed) with explosion control\n",
    "# - Draw unified panel by commune (publication, high resolution)\n",
    "# ============================================================\n",
    "\n",
    "import os, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "from datetime import datetime\n",
    "\n",
    "# If SciPy is available (usually yes), use it for Gamma CDF/PPF\n",
    "from scipy.stats import gamma as gamma_dist\n",
    "\n",
    "# -------------------- Configuration --------------------\n",
    "# Path to CSV with COPULA simulations generated in R\n",
    "COPULA_SIM_CSV = \"path/to/simulated_cases_severity_weighted_v2.csv\"\n",
    "\n",
    "# If you already have df_scaled in memory with the observed column OBS_COL, we'll use it.\n",
    "# If not, you can define OBS_DATA_CSV to load observed data from another file (optional).\n",
    "OBS_DATA_CSV = None  # e.g., \"/path/to/observed.csv\" with columns [\"Date\",\"Commune\",\"Observed_Cases\"]\n",
    "\n",
    "# Name of column with observed incidence in df_scaled or in OBS_DATA_CSV.\n",
    "# We'll try to detect automatically if not defined.\n",
    "OBS_COL = None  # e.g., \"Observed_Cases\" or \"Gross_Daily_Cases_Mobile_Average_7_Days\"\n",
    "\n",
    "# Target communes\n",
    "TARGET_COMMUNES = [\"La Florida\", \"Cerrillos\", \"Vitacura\", \"Providencia\", \"Las Condes\", \"Santiago\"]\n",
    "\n",
    "# Serial interval parameters (discretized Gamma)\n",
    "SI_MEAN, SI_SD, SI_MAX = 4.7, 2.9, 28\n",
    "\n",
    "# Cori: window and prior\n",
    "TAU = 7\n",
    "A0, B0 = 1.0, 1.0    # prior Gamma(shape=a0, rate=b0)\n",
    "CORI_Q = (0.05, 0.95)\n",
    "# Sampling for generative uncertainty mixing (Cori over simulations)\n",
    "MIX_SAMPLES_PER_PATH = 32\n",
    "\n",
    "# WT (stable)\n",
    "WT_MODE = \"sampled\"     # \"expected\" | \"sampled\"\n",
    "WT_B = 400\n",
    "WT_RIGHT_CENSOR = True\n",
    "WT_LMIN_MODE = \"relative\"  # 'relative' (to max(Λ)) or 'absolute'\n",
    "WT_LMIN_VAL = 1e-6\n",
    "\n",
    "# Output\n",
    "try:\n",
    "    OUT_DIR\n",
    "except NameError:\n",
    "    OUT_DIR = \"./eval_out\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# -------------------- SI kernel utilities --------------------\n",
    "def discretize_si_gamma(mean_si=SI_MEAN, sd_si=SI_SD, max_days=SI_MAX):\n",
    "    \"\"\"Discrete PMF w_s = F(s) - F(s-1) from Gamma(mean, sd).\"\"\"\n",
    "    var = sd_si**2\n",
    "    k = (mean_si**2) / var          # shape\n",
    "    theta = var / mean_si           # scale\n",
    "    s_grid = np.arange(0, max_days+1, dtype=float)\n",
    "    cdf = gamma_dist.cdf(s_grid, a=k, scale=theta)\n",
    "    w = np.diff(cdf)                # w[0] = P(0<SI<=1), etc.\n",
    "    w = np.maximum(w, 0.0)\n",
    "    w = w / w.sum()\n",
    "    return w\n",
    "\n",
    "def total_infectiousness(I, w):\n",
    "    \"\"\"Λ_t = sum_{s>=1} I_{t-s} w_s (with w[0] corresponding to s=1).\"\"\"\n",
    "    I = np.asarray(I, float)\n",
    "    T = len(I); W = np.zeros(T, dtype=float)\n",
    "    S = len(w)\n",
    "    for s in range(1, min(S, T) + 1):\n",
    "        W[s:] += I[:-s] * w[s-1]\n",
    "    return W\n",
    "\n",
    "# -------------------- Cori (observed and generative mixture) --------------------\n",
    "def cori_posterior_params(I, w, tau=7, a0=1.0, b0=1.0):\n",
    "    \"\"\"Returns arrays shape_t, rate_t for each t (NaN where no window).\"\"\"\n",
    "    I = np.asarray(I, float)\n",
    "    T = len(I)\n",
    "    L = total_infectiousness(I, w)\n",
    "    shape = np.full(T, np.nan)\n",
    "    rate  = np.full(T, np.nan)\n",
    "    for t in range(T):\n",
    "        u0 = t - tau + 1\n",
    "        if u0 < 0: \n",
    "            continue\n",
    "        Is = I[u0:t+1]\n",
    "        Ls = L[u0:t+1]\n",
    "        shape[t] = a0 + np.sum(Is)\n",
    "        rate[t]  = b0 + np.sum(Ls)\n",
    "    return shape, rate\n",
    "\n",
    "def cori_quantiles_from_params(shape, rate, q=(0.05, 0.95)):\n",
    "    \"\"\"Median and quantiles for Gamma(shape, rate).\"\"\"\n",
    "    med = np.full_like(shape, np.nan, dtype=float)\n",
    "    lo  = np.full_like(shape, np.nan, dtype=float)\n",
    "    hi  = np.full_like(shape, np.nan, dtype=float)\n",
    "    valid = np.isfinite(shape) & np.isfinite(rate) & (rate > 0) & (shape > 0)\n",
    "    if valid.any():\n",
    "        sc = 1.0 / rate[valid]\n",
    "        med[valid] = gamma_dist.ppf(0.5, a=shape[valid], scale=sc)\n",
    "        lo[valid]  = gamma_dist.ppf(q[0], a=shape[valid], scale=sc)\n",
    "        hi[valid]  = gamma_dist.ppf(q[1], a=shape[valid], scale=sc)\n",
    "    return med, lo, hi\n",
    "\n",
    "def cori_from_observed(I, w, tau=7, a0=1.0, b0=1.0, q=(0.05,0.95)):\n",
    "    shape, rate = cori_posterior_params(I, w, tau, a0, b0)\n",
    "    return cori_quantiles_from_params(shape, rate, q=q)\n",
    "\n",
    "def cori_from_ensemble(samples_matrix, w, tau=7, a0=1.0, b0=1.0, q=(0.05,0.95),\n",
    "                       mix_samples_per_path=32, seed=12345):\n",
    "    \"\"\"\n",
    "    Posterior mixture over simulations:\n",
    "    - for each simulation m and time t: posterior Gamma(shape_m[t], rate_m[t])\n",
    "    - sample K values and mix at level t; then compute quantiles.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    S = np.asarray(samples_matrix, float)           # (T, M)\n",
    "    T, M = S.shape\n",
    "    Rt_samples = np.full((T, M * mix_samples_per_path), np.nan, dtype=float)\n",
    "\n",
    "    for m in range(M):\n",
    "        shape, rate = cori_posterior_params(S[:, m], w, tau, a0, b0)\n",
    "        valid = np.isfinite(shape) & np.isfinite(rate) & (rate > 0) & (shape > 0)\n",
    "        if not valid.any():\n",
    "            continue\n",
    "        sc = 1.0 / rate[valid]\n",
    "        draws = rng.gamma(shape[valid][:, None], sc[:, None], size=(valid.sum(), mix_samples_per_path))\n",
    "        Rt_samples[valid, m*mix_samples_per_path:(m+1)*mix_samples_per_path] = draws\n",
    "\n",
    "    med = np.nanmedian(Rt_samples, axis=1)\n",
    "    lo  = np.nanquantile(Rt_samples, q[0], axis=1)\n",
    "    hi  = np.nanquantile(Rt_samples, q[1], axis=1)\n",
    "    return med, lo, hi\n",
    "\n",
    "# -------------------- Stable WT (observed) --------------------\n",
    "def wt_expected_stable(I, w, correct_right_censor=True, lmin_mode=\"relative\", lmin_val=1e-6):\n",
    "    \"\"\"\n",
    "    Stable version of WT 'expected':\n",
    "    R_t = sum_{s>=1, i=t+s} [ I[i] * w[s-1] / Λ[i] ] / sum_{valid s} w[s-1]\n",
    "    - Ignores terms with Λ[i] < Lmin (avoids explosions).\n",
    "    - If no valid mass at t, returns NaN and marks invalid.\n",
    "    \"\"\"\n",
    "    I = np.asarray(I, float)\n",
    "    T = len(I)\n",
    "    L = total_infectiousness(I, w)\n",
    "    Rt = np.full(T, np.nan)\n",
    "    valid = np.ones(T, dtype=int)\n",
    "\n",
    "    Lmax = np.nanmax(L) if np.isfinite(np.nanmax(L)) else 1.0\n",
    "    Lmin = (lmin_val * max(Lmax, 1e-12)) if (lmin_mode == \"relative\") else float(lmin_val)\n",
    "\n",
    "    for t in range(T):\n",
    "        max_s = min(len(w), T - t - 1)\n",
    "        if max_s <= 0:\n",
    "            Rt[t] = np.nan; valid[t] = 0; continue\n",
    "\n",
    "        num = 0.0\n",
    "        mass_valid = 0.0\n",
    "        for s in range(1, max_s + 1):\n",
    "            i = t + s\n",
    "            if L[i] >= Lmin:\n",
    "                num += I[i] * w[s-1] / L[i]\n",
    "                mass_valid += w[s-1]\n",
    "\n",
    "        if mass_valid <= 0:\n",
    "            Rt[t] = np.nan\n",
    "            valid[t] = 0\n",
    "            continue\n",
    "\n",
    "        Rt[t] = num / mass_valid\n",
    "\n",
    "    return Rt, valid\n",
    "\n",
    "def wt_bootstrap_stable(I, w, B=400, correct_right_censor=True,\n",
    "                        lmin_mode=\"relative\", lmin_val=1e-6,\n",
    "                        q_lo=0.05, q_hi=0.95, seed=123):\n",
    "    \"\"\"Stable parametric bootstrap: I* ~ Poisson(I); mix quantiles.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    T = len(I)\n",
    "    Rt_s = np.full((T, B), np.nan)\n",
    "    valid_last = None\n",
    "    for b in range(B):\n",
    "        I_b = rng.poisson(lam=np.maximum(I, 0.0))\n",
    "        Rt_b, valid_b = wt_expected_stable(I_b, w,\n",
    "                                           correct_right_censor=correct_right_censor,\n",
    "                                           lmin_mode=lmin_mode, lmin_val=lmin_val)\n",
    "        Rt_s[:, b] = Rt_b\n",
    "        valid_last = valid_b\n",
    "    Rt_med = np.nanmedian(Rt_s, axis=1)\n",
    "    Rt_lo  = np.nanquantile(Rt_s, q_lo, axis=1)\n",
    "    Rt_hi  = np.nanquantile(Rt_s, q_hi, axis=1)\n",
    "    return Rt_med, Rt_lo, Rt_hi, valid_last\n",
    "\n",
    "# -------------------- Data loading (simulations + observed) --------------------\n",
    "def load_copula_simulations(csv_path):\n",
    "    \"\"\"\n",
    "    Reads CSV with columns: Date, Commune, X1..XM\n",
    "    Returns dict[commune] -> {\"dates\": list[pd.Timestamp], \"samples\": np.array shape (T, M)}\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path, parse_dates=[\"Date\"])\n",
    "    # Detect simulation columns (X1, X2, ...)\n",
    "    sim_cols = [c for c in df.columns if c.startswith(\"X\")]\n",
    "    if len(sim_cols) == 0:\n",
    "        raise ValueError(\"No simulation columns found (prefix 'X').\")\n",
    "    out = {}\n",
    "    for comm, d in df.groupby(\"Commune\"):\n",
    "        d = d.sort_values(\"Date\").reset_index(drop=True)\n",
    "        out[comm] = {\n",
    "            \"dates\": pd.to_datetime(d[\"Date\"]).tolist(),\n",
    "            \"samples\": d[sim_cols].to_numpy(dtype=float)  # (T, M)\n",
    "        }\n",
    "    return out\n",
    "\n",
    "def load_observed_frame(OBS_COL_name=None, obs_csv=None):\n",
    "    \"\"\"\n",
    "    Gets DataFrame with columns ['Date','Commune', OBS_COL].\n",
    "    - If global df_scaled exists and OBS_COL_name is in df_scaled, use that.\n",
    "    - If OBS_COL_name is None, try to guess.\n",
    "    - If obs_csv is not None, load it and require OBS_COL_name.\n",
    "    \"\"\"\n",
    "    # 1) Is df_scaled already in memory?\n",
    "    df_src = None\n",
    "    try:\n",
    "        df_scaled  # noqa\n",
    "        df_src = df_scaled.copy()\n",
    "    except NameError:\n",
    "        df_src = None\n",
    "\n",
    "    if df_src is not None:\n",
    "        candidates = []\n",
    "        if OBS_COL_name is not None:\n",
    "            candidates = [OBS_COL_name]\n",
    "        else:\n",
    "            # try to detect\n",
    "            for cand in [\"Observed_Cases\", \"OBS_COL\", \"Gross_Daily_Cases_Mobile_Average_7_Days\", \"Cases\"]:\n",
    "                if cand in df_src.columns:\n",
    "                    candidates.append(cand)\n",
    "        if not candidates:\n",
    "            # fall back to external CSV\n",
    "            df_src = None\n",
    "        else:\n",
    "            col = candidates[0]\n",
    "            return df_src[[\"Date\",\"Commune\", col]].rename(columns={col: \"OBSERVED\"}).assign(Date=pd.to_datetime(df_src[\"Date\"]))\n",
    "\n",
    "    # 2) External CSV\n",
    "    if obs_csv is not None:\n",
    "        df = pd.read_csv(obs_csv, parse_dates=[\"Date\"])\n",
    "        if OBS_COL_name is None:\n",
    "            for cand in [\"Observed_Cases\", \"Gross_Daily_Cases_Mobile_Average_7_Days\", \"Cases\"]:\n",
    "                if cand in df.columns:\n",
    "                    OBS_COL_name = cand; break\n",
    "        if OBS_COL_name is None or OBS_COL_name not in df.columns:\n",
    "            raise ValueError(\"Could not determine observed column in OBS_DATA_CSV.\")\n",
    "        return df[[\"Date\",\"Commune\", OBS_COL_name]].rename(columns={OBS_COL_name:\"OBSERVED\"})\n",
    "\n",
    "    raise RuntimeError(\"No observed data found. Define df_scaled with cases column or provide OBS_DATA_CSV.\")\n",
    "\n",
    "# -------------------- Pipeline: Cori (obs & Copula) + WT --------------------\n",
    "def run_rt_all_copula(df_obs, copula_dict, communes, si_mean=SI_MEAN, si_sd=SI_SD, si_max=SI_MAX,\n",
    "                      tau=TAU, a0=A0, b0=B0, cori_q=CORI_Q,\n",
    "                      mix_samples_per_path=MIX_SAMPLES_PER_PATH,\n",
    "                      wt_mode=WT_MODE, wt_B=WT_B, wt_right_censor=WT_RIGHT_CENSOR,\n",
    "                      wt_lmin_mode=WT_LMIN_MODE, wt_lmin_val=WT_LMIN_VAL):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      RT_RES[comm] -> {dates, Rt_obs_median/lo/hi, Rt_gen_median/lo/hi}\n",
    "      WT_RES[comm] -> {dates, Rt_median/lo/hi, valid}\n",
    "    \"\"\"\n",
    "    w = discretize_si_gamma(si_mean, si_sd, si_max)\n",
    "    RT_RES, WT_RES = {}, {}\n",
    "    groups = df_obs.groupby(\"Commune\")\n",
    "\n",
    "    for comm in communes:\n",
    "        if comm not in copula_dict:\n",
    "            continue\n",
    "        # Observed data\n",
    "        if comm not in groups.groups:\n",
    "            continue\n",
    "        d = groups.get_group(comm).sort_values(\"Date\").reset_index(drop=True)\n",
    "        dates_obs = pd.to_datetime(d[\"Date\"]).tolist()\n",
    "        I_obs = d[\"OBSERVED\"].to_numpy(dtype=float)\n",
    "        I_obs = np.clip(I_obs, a_min=0.0, a_max=None)\n",
    "\n",
    "        # Cori (observed)\n",
    "        obs_med, obs_lo, obs_hi = cori_from_observed(I_obs, w, tau=tau, a0=a0, b0=b0, q=cori_q)\n",
    "\n",
    "        # Cori (COPULA: posterior mixture over simulations)\n",
    "        samples = copula_dict[comm][\"samples\"]  # (T, M)\n",
    "        # Ensure dates align (we'll assume they do by construction; if not, do a merge by Date)\n",
    "        gen_med, gen_lo, gen_hi = cori_from_ensemble(samples, w, tau=tau, a0=a0, b0=b0,\n",
    "                                                     q=cori_q, mix_samples_per_path=mix_samples_per_path)\n",
    "\n",
    "        RT_RES[comm] = {\n",
    "            \"dates\": dates_obs,\n",
    "            \"Rt_obs_median\": obs_med.tolist(),\n",
    "            \"Rt_obs_lo\":     obs_lo.tolist(),\n",
    "            \"Rt_obs_hi\":     obs_hi.tolist(),\n",
    "            \"Rt_gen_median\": gen_med.tolist(),\n",
    "            \"Rt_gen_lo\":     gen_lo.tolist(),\n",
    "            \"Rt_gen_hi\":     gen_hi.tolist(),\n",
    "        }\n",
    "\n",
    "        # WT (observed) stable\n",
    "        if wt_mode == \"expected\":\n",
    "            Rt_wt, valid = wt_expected_stable(I_obs, w,\n",
    "                                              correct_right_censor=wt_right_censor,\n",
    "                                              lmin_mode=wt_lmin_mode, lmin_val=wt_lmin_val)\n",
    "            WT_RES[comm] = {\n",
    "                \"dates\": dates_obs,\n",
    "                \"Rt_median\": Rt_wt.tolist(),\n",
    "                \"Rt_lo\": Rt_wt.tolist(),\n",
    "                \"Rt_hi\": Rt_wt.tolist(),\n",
    "                \"valid\": valid.tolist()\n",
    "            }\n",
    "        else:\n",
    "            Rt_med, Rt_lo, Rt_hi, valid = wt_bootstrap_stable(I_obs, w, B=wt_B,\n",
    "                                                              correct_right_censor=wt_right_censor,\n",
    "                                                              lmin_mode=wt_lmin_mode, lmin_val=wt_lmin_val)\n",
    "            WT_RES[comm] = {\n",
    "                \"dates\": dates_obs,\n",
    "                \"Rt_median\": Rt_med.tolist(),\n",
    "                \"Rt_lo\": Rt_lo.tolist(),\n",
    "                \"Rt_hi\": Rt_hi.tolist(),\n",
    "                \"valid\": valid.tolist()\n",
    "            }\n",
    "\n",
    "    return RT_RES, WT_RES\n",
    "\n",
    "# -------------------- Unified plot --------------------\n",
    "def _series_from(dict_, keys, name):\n",
    "    ds = pd.to_datetime(pd.Series(dict_[keys[\"date\"]], dtype=\"object\"))\n",
    "    df = pd.DataFrame({\n",
    "        f\"{name}_med\": dict_[keys[\"med\"]],\n",
    "        f\"{name}_lo\":  dict_[keys[\"lo\"]],\n",
    "        f\"{name}_hi\":  dict_[keys[\"hi\"]],\n",
    "    }, index=ds)\n",
    "    df = df[~df.index.duplicated(keep=\"first\")].sort_index()\n",
    "    return df\n",
    "\n",
    "def _last_invalid_span(valid_arr):\n",
    "    v = np.asarray(valid_arr, int)\n",
    "    if v.size == 0 or v[-1] != 0:\n",
    "        return None\n",
    "    i = len(v) - 1\n",
    "    while i >= 0 and v[i] == 0:\n",
    "        i -= 1\n",
    "    return i + 1\n",
    "\n",
    "def plot_rt_unified_panels_general(\n",
    "    RT_RES, WT_RES, communes=TARGET_COMMUNES,\n",
    "    gen_name=\"Copula\", ncols=2, fig_width=16, row_height=5.0,\n",
    "    save_path=None, title=None, force_ylim=True\n",
    "):\n",
    "    plt.rcParams.update({\n",
    "        \"font.family\": \"DejaVu Sans\",\n",
    "        \"axes.titlesize\": 12.5,\n",
    "        \"axes.labelsize\": 12,\n",
    "        \"xtick.labelsize\": 10,\n",
    "        \"ytick.labelsize\": 10,\n",
    "        \"legend.fontsize\": 10.5,\n",
    "        \"savefig.dpi\": 600,\n",
    "    })\n",
    "    col_obs_band = \"#808080\"; col_obs_line = \"#222222\"\n",
    "    col_gen_band = \"#4C78A8\"; col_gen_line = \"#2F5B8B\"\n",
    "    col_wt_band  = \"#59A14F\"; col_wt_line  = \"#2E7D32\"\n",
    "    a_obs, a_gen, a_wt = 0.18, 0.22, 0.22\n",
    "    lw = 2.0\n",
    "\n",
    "    n = len(communes); nrows = int(math.ceil(n / ncols))\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(fig_width, row_height*nrows), sharex=False, sharey=False)\n",
    "    axes = np.array(axes).reshape(-1)\n",
    "\n",
    "    for ax, comm in zip(axes, communes):\n",
    "        if comm not in RT_RES or comm not in WT_RES:\n",
    "            ax.text(0.5, 0.5, f\"No data for {comm}\", ha=\"center\", va=\"center\", transform=ax.transAxes)\n",
    "            ax.axis(\"off\"); continue\n",
    "\n",
    "        rt = RT_RES[comm]; wt = WT_RES[comm]\n",
    "        df_obs = _series_from(rt, {\"date\":\"dates\",\"med\":\"Rt_obs_median\",\"lo\":\"Rt_obs_lo\",\"hi\":\"Rt_obs_hi\"}, \"obs\")\n",
    "        df_gen = _series_from(rt, {\"date\":\"dates\",\"med\":\"Rt_gen_median\",\"lo\":\"Rt_gen_lo\",\"hi\":\"Rt_gen_hi\"}, \"gen\")\n",
    "        df_wt  = _series_from(wt, {\"date\":\"dates\",\"med\":\"Rt_median\",\"lo\":\"Rt_lo\",\"hi\":\"Rt_hi\"}, \"wt\")\n",
    "\n",
    "        df = df_obs.join(df_gen, how=\"inner\").join(df_wt, how=\"inner\")\n",
    "        if df.empty:\n",
    "            ax.text(0.5,0.5,f\"No aligned dates for {comm}\",ha=\"center\",va=\"center\",transform=ax.transAxes)\n",
    "            ax.axis(\"off\"); continue\n",
    "\n",
    "        dates = df.index\n",
    "\n",
    "        # Bands\n",
    "        ax.fill_between(dates, df[\"obs_lo\"], df[\"obs_hi\"], color=col_obs_band, alpha=a_obs, edgecolor=\"none\")\n",
    "        ax.fill_between(dates, df[\"gen_lo\"], df[\"gen_hi\"], color=col_gen_band, alpha=a_gen, edgecolor=\"none\")\n",
    "        ax.fill_between(dates, df[\"wt_lo\"],  df[\"wt_hi\"],  color=col_wt_band,  alpha=a_wt,  edgecolor=\"none\")\n",
    "\n",
    "        # Medians\n",
    "        ax.plot(dates, df[\"obs_med\"], color=col_obs_line, lw=lw)\n",
    "        ax.plot(dates, df[\"gen_med\"], color=col_gen_line, lw=lw)\n",
    "        ax.plot(dates, df[\"wt_med\"],  color=col_wt_line,  lw=lw)\n",
    "\n",
    "        # Rt=1\n",
    "        ax.axhline(1.0, color=\"#000000\", lw=1.0, ls=\":\", alpha=0.85)\n",
    "\n",
    "        # Shade invalid span at the end (WT)\n",
    "        if \"valid\" in wt and len(wt[\"valid\"]) == len(wt[\"dates\"]):\n",
    "            idx0 = _last_invalid_span(wt[\"valid\"])\n",
    "            if idx0 is not None and idx0 < len(wt[\"dates\"]):\n",
    "                t0 = pd.to_datetime(wt[\"dates\"][idx0]); t1 = pd.to_datetime(wt[\"dates\"][-1])\n",
    "                ax.axvspan(t0, t1, color=\"#9E9E9E\", alpha=0.12, lw=0, zorder=0)\n",
    "\n",
    "        # Vertical range (optional, helps see Rt=1)\n",
    "        if force_ylim:\n",
    "            q98 = np.nanquantile(np.r_[df[\"obs_med\"].values, df[\"gen_med\"].values, df[\"wt_med\"].values], 0.98)\n",
    "            ylim_top = max(2.5, float(q98))\n",
    "            ax.set_ylim(0.0, ylim_top)\n",
    "\n",
    "        ax.set_title(comm); ax.set_ylabel(r\"$R_t$\"); ax.grid(True, alpha=0.3)\n",
    "\n",
    "    for k in range(len(communes), len(axes)):\n",
    "        axes[k].axis(\"off\")\n",
    "\n",
    "    legend_elems = [\n",
    "        Patch(facecolor=col_obs_band, edgecolor=\"none\", alpha=a_obs, label=\"Cori (obs) 95% band\"),\n",
    "        Line2D([0],[0], color=col_obs_line, lw=lw, label=\"Cori (obs) median\"),\n",
    "        Patch(facecolor=col_gen_band, edgecolor=\"none\", alpha=a_gen, label=f\"Cori ({gen_name}) 90% band\"),\n",
    "        Line2D([0],[0], color=col_gen_line, lw=lw, label=f\"Cori ({gen_name}) median\"),\n",
    "        Patch(facecolor=col_wt_band,  edgecolor=\"none\", alpha=a_wt,  label=\"WT 90% band\"),\n",
    "        Line2D([0],[0], color=col_wt_line,  lw=lw, label=\"WT median\"),\n",
    "        Line2D([0],[0], color=\"#000000\", lw=1.0, ls=\":\", label=r\"$R_t=1$\")\n",
    "    ]\n",
    "    fig.legend(legend_elems, [h.get_label() for h in legend_elems],\n",
    "               loc=\"lower center\", ncol=4, frameon=False)\n",
    "\n",
    "    if title is None:\n",
    "        title = r\"Time-varying reproduction number $R_t$: Cori (obs \\& Copula) and WT\"\n",
    "    fig.suptitle(title, y=0.995, fontsize=14)\n",
    "\n",
    "    fig.tight_layout(rect=[0,0.05,1,0.98])\n",
    "    if save_path is None:\n",
    "        save_path = os.path.join(OUT_DIR, \"rt_unified_panels_copula.png\")\n",
    "    fig.savefig(save_path, dpi=600, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"✓ Saved:\", save_path)\n",
    "\n",
    "# -------------------- Run everything --------------------\n",
    "# 1) Copula simulations\n",
    "COPULA_ENS = load_copula_simulations(COPULA_SIM_CSV)\n",
    "\n",
    "# 2) Observed data\n",
    "df_obs = load_observed_frame(OBS_COL_name=OBS_COL, obs_csv=OBS_DATA_CSV)\n",
    "\n",
    "# 3) Filter to target communes and align dates (optional: here we assume they're consistent)\n",
    "df_obs = df_obs[df_obs[\"Commune\"].isin(TARGET_COMMUNES)].copy()\n",
    "\n",
    "# 4) Calculate Rt (Cori obs/copula + stable WT)\n",
    "RT_RES, WT_RES = run_rt_all_copula(\n",
    "    df_obs=df_obs,\n",
    "    copula_dict=COPULA_ENS,\n",
    "    communes=TARGET_COMMUNES,\n",
    "    si_mean=SI_MEAN, si_sd=SI_SD, si_max=SI_MAX,\n",
    "    tau=TAU, a0=A0, b0=B0, cori_q=CORI_Q,\n",
    "    mix_samples_per_path=MIX_SAMPLES_PER_PATH,\n",
    "    wt_mode=WT_MODE, wt_B=WT_B, wt_right_censor=WT_RIGHT_CENSOR,\n",
    "    wt_lmin_mode=WT_LMIN_MODE, wt_lmin_val=WT_LMIN_VAL\n",
    ")\n",
    "\n",
    "# 5) Unified visualization\n",
    "plot_rt_unified_panels_general(\n",
    "    RT_RES=RT_RES,\n",
    "    WT_RES=WT_RES,\n",
    "    communes=TARGET_COMMUNES,\n",
    "    gen_name=\"Copula\",\n",
    "    ncols=2,\n",
    "    fig_width=16,\n",
    "    row_height=5.0,\n",
    "    save_path=os.path.join(OUT_DIR, \"rt_unified_panels_copula.png\"),\n",
    "    title=r\"Time-varying reproduction number $R_t$: Cori (obs \\& Copula) and WT\",\n",
    "    force_ylim=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
